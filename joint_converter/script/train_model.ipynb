{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARTIFICIAL NEURAL NETWORK \n",
    "### NOTE: USE IN GOOGLE COLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "torch.manual_seed(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(filepath, right_arm=False):\n",
    "    data0 = pd.read_csv(filepath + \".csv\")\n",
    "    data1 = pd.read_csv(filepath + \"1.csv\")\n",
    "    data2 = pd.read_csv(filepath + \"2.csv\")\n",
    "    df = pd.concat([data0, data1, data2], ignore_index=True)\n",
    "    X = \"R\" if right_arm else \"L\"\n",
    "    angle_names = [\"{}ShoulderPitch\".format(X),\n",
    "                   \"{}ShoulderRoll\".format(X),\n",
    "                   \"{}ElbowYaw\".format(X),\n",
    "                   \"{}ElbowRoll\".format(X)]\n",
    "    labels = df[angle_names]\n",
    "    data = df[[column for column in df.columns if column not in angle_names]]\n",
    "    # filter corrupted data!!!\n",
    "    data = data.drop_duplicates(keep=False)\n",
    "    labels = labels.loc[data.index]\n",
    "\n",
    "    data, labels = torch.Tensor(data.values), torch.Tensor(labels.values)\n",
    "    return Data.TensorDataset(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net(net_version=None):\n",
    "    if net_version == 0:\n",
    "        net = nn.Sequential(\n",
    "                    nn.Linear(6, 200),\n",
    "                    nn.LeakyReLU(),\n",
    "                    nn.Linear(200, 100),\n",
    "                    nn.LeakyReLU(),\n",
    "                    nn.Linear(100, 100),\n",
    "                    nn.LeakyReLU(),\n",
    "                    nn.Linear(100, 100),\n",
    "                    nn.LeakyReLU(),\n",
    "                    nn.Linear(100, 100),\n",
    "                    nn.LeakyReLU(),\n",
    "                    nn.Linear(100, 100),\n",
    "                    nn.LeakyReLU(),\n",
    "                    nn.Linear(100, 100),\n",
    "                    nn.LeakyReLU(),\n",
    "                    nn.Linear(100, 100),\n",
    "                    nn.LeakyReLU(),\n",
    "                    nn.Linear(100, 100),\n",
    "                    nn.LeakyReLU(),\n",
    "                    nn.Linear(100, 50),\n",
    "                    nn.LeakyReLU(),\n",
    "                    nn.Linear(50, 4)\n",
    "                )\n",
    "    else:\n",
    "        net = nn.Sequential(\n",
    "                    nn.Linear(6, 200),\n",
    "                    nn.LeakyReLU(),\n",
    "                    nn.Linear(200, 100),\n",
    "                    nn.LeakyReLU(),\n",
    "                    nn.Linear(100, 4)\n",
    "                )\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ann(filepath, net=None, batch_size=10000, epoch=300, learning_rate=0.01, decay=0, net_version=0):\n",
    "\n",
    "    dataset = get_dataset(filepath)\n",
    "    loader = Data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    \n",
    "    if net is None:\n",
    "        net = get_net(net_version)\n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "        print('CUDA is available!  Training on GPU ...')\n",
    "\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=decay)\n",
    "    loss_func = nn.MSELoss()\n",
    "\n",
    "    iters, losses = [], []\n",
    "    n = 0\n",
    "    best_result = np.inf\n",
    "    best_epoch = 0\n",
    "    for epoch in range(epoch):\n",
    "        error = np.array([0.0, 0.0, 0.0, 0.0])\n",
    "        for step, (data, labels) in enumerate(loader):\n",
    "            #############################################\n",
    "            #To Enable GPU Usage\n",
    "            if torch.cuda.is_available():\n",
    "                data = data.cuda()\n",
    "                labels = labels.cuda()\n",
    "            #############################################\n",
    "            prediction = net(data)\n",
    "            loss = loss_func(prediction, labels) \n",
    "            loss.backward()         # backpropagation, compute gradients\n",
    "            optimizer.step()        # apply gradients\n",
    "            optimizer.zero_grad()   # clear gradients for next train\n",
    "            \n",
    "            iters.append(n)\n",
    "            losses.append(float(loss)/batch_size)             # compute *average* loss\n",
    "            n += 1\n",
    "\n",
    "            for x in range(4):\n",
    "                if torch.cuda.is_available():\n",
    "                    error[x] += mean_absolute_error(prediction[:, x].cpu().detach().numpy(), labels[:,x].cpu().detach().numpy())\n",
    "                else:\n",
    "                    error[x] += mean_absolute_error(prediction[:, x].detach().numpy(), labels[:,x].detach().numpy())\n",
    "        print(\"Epoch: {}, Error: {}\".format(epoch, error / step))\n",
    "        \n",
    "        if sum(error) < best_result:\n",
    "            best_result = sum(error)\n",
    "            best_epoch = epoch\n",
    "            print(\"Best result at Epoch {}. Saving model parameters.\".format(epoch))\n",
    "            model_path = \"ann_epoch{}\".format(epoch)\n",
    "            torch.save(net.state_dict(), model_path)   \n",
    "            \n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            # saving the best model at my local google drive for every 100th epoch\n",
    "            model_path = \"ann_epoch{}\".format(best_epoch)\n",
    "            state = torch.load(model_path)\n",
    "            net.load_state_dict(state)\n",
    "            model_path = \"/content/drive/My Drive/Thesis/left_arm_ANN_model\"\n",
    "            torch.save(net.state_dict(), model_path)\n",
    "\n",
    "    # plotting\n",
    "    plt.title(\"Training Curve\")\n",
    "    plt.plot(iters, losses, label=\"Train\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_arm_filepath = \"/content/drive/My Drive/Thesis/left_arm_data\"\n",
    "net = get_net()\n",
    "train_ann(left_arm_filepath, net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
